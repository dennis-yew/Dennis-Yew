<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Post</title>
    <link rel="stylesheet" href="posts.css"> 
</head>
<!-- 导航栏 -->
<nav class="navbar">
    <a href="#">首页</a>
    <a href="#">关于我</a>
    <a href="#">联系</a>
</nav>

<!-- 博客标题 -->
<header>
    <h1>Welcome to my personal blog on GitHub!</h1>
</header>

<body>
<h1>GBDT 梯度提升树</h1>
<p>梯度提升树的原理与残差拟合类似，就是先通过一棵树对模型进行拟合，拟合出来的结果与实际观测值会有残差。我们继续训练一棵新的树，去拟合这个残差。然后，我们将新树的预测结果与原来的模型预测结果相加，得到一个新的、更准确的预测结果。这里我给一个一元回归的残差分析例子</p> 
<h2>决策树的基本原理</h2>
<P>本质思维，考虑什么最重要，下一个是什么, 也就是给所有的因子划分重要的顺序, 这和赋予权重不太一样</P>
决策树在选择每一层的因子的标准是基尼系数最小，为什么
决策树算法中常用的一个不纯度指标。当我们在构建决策树时，会不断地对数据进行分割，以找到最佳的分裂点。而基尼系数最小，就意味着分裂后的数据集纯度最高，即同一类别的数据被分到了一起。
<script src="https://d3js.org/d3.v7.min.js"></script>

<div id="tree-chart"></div>
<script src="/posts/20240830.js"></script>
<h2>简单线性回归的残差分析</h2>
<p>简单线性回归 有两个基本假设第一个基本假设是符合A + B X + e;第二个基本假设是,e的残差服从均值为零,方差为一个固定值的正态分布:N(0,o^2)</p>
<p> 而所谓的残差，就 预测值与观测值之间的差， 也是公式中的e,因此残差检验的意义在于：检测第二步假设, 看到是否符合均值为零的正态分布</p>
<p> 至于如何检验残渣服从正态分布常见的方式是通过化残插图来观察，如果 如果长差的分布介于两条平行线之间，而且均值大致为零，且不随自变量X移动，那么我们就认为他是符合正态分布的，如果画出来的长插图，发现它会随着X移动，或者呈现出凹型或者凸形， 那就说明模型假设的e有错误，我们需要更改模型为多元回归或者是曲线回归</p>
<p> 由于他符合整台分布，因此我们可以将它标准化用长叉除以估计的标准差来对参差进行标准化标准化之后的数据通过长插图表现出来就应该是在所有的点至少95%的点必须要分布在正二和-2之间</p>




<!-- 页脚 -->
<footer class="footer">
    <p>© 2024 我的博客. 保留所有权利.</p>
</footer>
</body>
</html>